\documentclass[a4paper]{llncs}

\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc} 
\input{utf8symbols}
\usepackage{stmaryrd}
\usepackage{amsmath,amssymb}
\usepackage{mathpartir}

\newcommand{\wpre}{{\bf wp}}
\newcommand{\sep}{ ~|~ }
\newcommand{\letml}{{\bf let}}
\newcommand{\inml}{{\bf in}}
\newcommand{\ifml}{{\bf if}}
\newcommand{\thenml}{{\bf then}}
\newcommand{\elseml}{{\bf else}}
\newcommand{\refml}{{\bf ref}}
\newcommand{\propml}{{\bf prop}}
\newcommand{\boolml}{{\bf bool}}
\newcommand{\recml}{{\bf rec}}
\newcommand{\efft}[1]{\langle #1 \rangle}
\newcommand{\lift}[1]{\langle #1 \rangle}
\newcommand{\alist}[1]{\overline{#1} }
\newcommand{\Trueml}{{\bf True}}
\newcommand{\Falseml}{{\bf False}}
\newcommand{\trueml}{{\bf true}}
\newcommand{\falseml}{{\bf false}}
\newcommand{\unitml}{{\bf unit}}
\newcommand{\coq}{Coq}
\newcommand{\who}{Who}
\newcommand{\correct}[1]{c(#1)}

\newcommand{\ceil}[1]{\lceil #1 \rceil}

\begin{document}
\title{\mbox{Specifying Imperative Higher Order Programs}}

\author{Johannes Kanig \and Jean-Christophe Fill\^atre}
\institute{
Laboratoire de Recherche en Informatique, Univ Paris-Sud, CNRS, Orsay F-91405\\
INRIA Futurs, ProVal, Parc Orsay Universit\'e, F-91893
}
%TODO affiliation
%TODO find notions for:
%  * ``semantic values'' v
%  * ``store types'' <ε>
% 


\maketitle

% ICFP
%  We present a weakest precondition calculus for an imperative,
%  higher-order programming language, restricted to non-aliasing global
%  references. The main feature of the calculus is {\em effect
%    polymorphism}, {\em i.e.}, higher-order functions can be specified by
%  generalizing over the effects and specifications of their functional
%  arguments. This allows truly modular reasoning about effectful
%  higher-order functions. We achieve this by defining an extension of
%  a standard higher-order logic, more suitable to reason about
%  modifications of the store. The obtained proof obligations, however,
%  are expressible in the standard logic and can be proved using
%  standard theorem provers. We show that the necessary annotations
%  and the obtained proof obligations are quite natural.
%

% Workshop ML
%  We present \who, a tool for verifying effectful higher-order
%  functions. It features {\em Effect polymorphism}, higher-order logic
%  and the possibility to reason about state in the logic, which enable
%  highly modular specifications of generic code. Several small
%  examples and a larger case study demonstrate its usefulness. The
%  \who~tool is intended to be used as an intermediate language for
%  verification tools targeting ML-like programming languages.
%

\begin{abstract} We present a specification language suited for reasoning
  about effectful higher-order programs. The language's main features are
  higher-order logic and effect polymorphism, both of which enable a truly
  modular treatment of higher-order functions. To our knowledge, this is the
  first time that effect polymorphism is put to use in program verification.
  We also define a weakest precondition calculus for this language which
  generates proof obligations in higher-order logic. A simple mechanism based
  on regions permits to restrict the analysis to alias-free programs, thus
  obtaining much simpler proof obligations. Several examples demonstrate the
  practicality of the system. A prototype implementation exists and has been
  used to prove the correctness of these and more examples.  
\end{abstract}


\section{Introduction}
%TODO Hoare logic = sharing between logic and prog language + alias free

also one or two examples in the described language

characteristics : 
\begin{itemize}
  \item Hoare logic
  \item logic and program share values  
  \item Type and effect system
  \item Region typing to track references
  \item the wp needs absence of aliasing to produce good POs
\end{itemize}

\section{A programming language for specification}

technical presentation:
\begin{itemize}
  \item ANF
  \item values defined by typing 
  \item  two different types of arrows
  \item  distinction bool and prop
  \item  notion of substitution - correspondence χ κ
  \item semantics is standard (goes to appendix )
\end{itemize}

\subsection{Syntax}
\begin{figure}[htpb]
\begin{eqnarray*}
  x & & \text{Program Variables}\\
  α & & \text{Type Variables}\\
  e & & \text{Effect Variables}\\
  ρ & & \text{Region Variables}\\
  χ &::=& α \sep e \sep ρ \\
  t,p,q &::=& x~[\alist{κ}] \sep λx:τ.t \sep \recml~f~(x:τ).\{p\}t\{q\} \sep t~t\sep \\ 
  & & \letml~ x~[\alist{χ}] = t~\inml~t \sep \ifml~t~\thenml~t~\elseml~t\\
  τ &::=& α \sep τ -> τ \sep τ ->^ε τ \sep τ \times τ \sep τ~\refml_ρ \sep
  \efft{ε} \\
  ε &::=& (ρ \sep e)*\\
  κ &::=& τ \sep ε \sep ρ
\end{eqnarray*}
  \caption{Syntax}
  \label{fig:syntax}
\end{figure}

Our programming language (Fig.~\ref{fig:syntax}) is basically the λ-calculus
with \letml-bindings, where there are two different λ-bindings. The first one
($λx:τ.t$) describes a pure, non-recursive binding, and the second one
($\recml~f~(x:τ).\{p\}t\{q\}$) describes recursive, potentially impure
functions; $p$ and $q$ in this term are {\em specifications}, which are
of the same syntax as programs, but are differently typed (typing will be
discussed in the next section). The term $p$ corresponds to the {\em
precondition}, $q$ to the {\em postcondition} of the function. The analogy to
Hoare triples is of course obvious. As usual, there are also variables,
\letml-bindings and an \ifml-\thenml-\elseml-construct. Variables on the type
level can be generalized at \letml-boundaries and have to be instantiated when
the corresponding program variable is used.

Before we describe the syntax of types, let us first explain {\em regions} and
{\em effects}. Regions are simply type level names for memory locations. An
effect is a set of memory locations and {\em effect variables}. An effect
variable stands for an unknown effect. Effects are used to specify
of memory locations an expression can write. They are also used in function
types to describe the memory locations which may be written if the function is
called.

Type, region and effect variables must be explicitly generalized and
instantiated. For this purpose, we have defined the metavariable $χ$,
representing variables, and $κ$, representing the corresponding instantiation
objects types, regions and effects\footnote{We do not distinguish between
region variables and region constants; a region constant is simply a region
variable whose scope is the entire program.}. Now, it can be seen that
generalization takes place at \letml-bindings and instantiation at variable
occurrences. We use a horizontal bar over terms (like in ${\overline{χ}}$) to
denote lists.

\subsection{Typing}

We have already seen that programs and specification share in fact the same
syntax. Though they are differently typed, their typing relations still share
a lot. For this reason, and to underline the fact that in Hoare logic, values
are shared between programs and the logic, we present three different typing
relations. One for programs, one for specifications, and the common part is
factored out in a third typing relation for values. All typing relations
contain an environment $Γ$, which is simply a map from variable names to {\em
type schemes} of the form $∀\alist{χ}.τ$ .

\begin{figure}[htbp]
  \begin{mathpar}
  { \inferrule*[Left=Var] {Γ(x) = ∀\alist{χ}.τ} {Γ|-_v x~[\alist{κ}] :
  τ[\alist{χ}|->\alist{κ}]} } \and
  { \inferrule*[Left=PureFun] {Γ,x : τ' |-_v t : τ} {Γ|-_v λx : τ'.t : τ' ->
  τ} } \and
  { \inferrule*[Left=Rec] 
  { Γ' = Γ, x : τ' \\ Γ'' = Γ',~f : τ' ->^ε τ \\ Γ'' |- t : τ,ε \\ Γ' |-_l
  p : \efft{ε} -> \propml \\ Γ' |-_l q : \efft{ε} ->
  \efft{ε} -> τ -> \propml } 
      {Γ|-_v \recml~f~(x : τ').\{p\}t\{q\} : τ' ->^ε τ} 
  } \and
  { \inferrule*[Left=PureApp]
    {Γ |-_v t1 : τ' -> τ \\ Γ|-_v t2 : τ'}
    {Γ |-_v  t1 ~ t2 : τ}
  }
  \end{mathpar}
  \caption{Value typing}
  \label{fig:valuetyping}
\end{figure}

\paragraph{Value typing.}
Let us first look at the common part concerning values. We define a relation
$Γ|-_v t : τ$, which means ``$t$ is well-typed wrt. the environment $Γ$, and
is of type $τ$''. Values cannot have any effect.  Variables and pure
abstractions are typed in the usual way; type instantiations at variable
occurences are substituted in the type. The rule {\sc REC} simply states that
the body of the function can use the argument $x$ as well as the function $f$.
The specifications $p$ and $q$, however, cannot use $f$ and must be well-typed
wrt. the typing relation $|-_l$ described later on. Finally, pure applications
between values are considered as values as well, as they don't have any
effect.

\begin{figure}[htpb]
\begin{mathpar}
  { \inferrule*[Left=Value]
  { Γ |-_v t : τ  }
  { Γ |- t : τ,\emptyset  }
  } \and
  { \inferrule*[Left=App]
    {Γ |-_v t1 : τ' ->^ε τ \\ Γ|-_v t2 : τ'}
    {Γ |- t1 ~ t2 : τ, ε}
  } \and
  { \inferrule*[Left=ite]
    { Γ |- _v t1 : \boolml \\ Γ |- t2 : τ, ε1 \\ Γ |- t3 : τ, ε2 }
    { Γ |- \ifml~ t1 ~\thenml~ t2 ~\elseml ~ t3 : τ, ε1  ε2 }
  } \and
  { \inferrule*[Left=Letv]
    { Γ, \alist{χ} |-_v t1 : τ' \\ Γ, x : ∀\alist{χ}.τ' |- t2 : τ,ε }
    { Γ |- \letml~ x~[\alist{χ}] = t1 ~ \inml~ t2 : τ, ε}
  } \and
  { \inferrule*[Left=Let]
    { Γ |- t1 : τ', ε \\ Γ, x : τ' |- t2 : τ, ε }
    { Γ |- \letml~ x = t1 ~ \inml~ t2 : τ, ε }
  } \and
  { \inferrule*[Left=Sub]
    { Γ |- t : τ', ε \\ ε \subseteq ε' }
    { Γ |- t : τ, ε' }
  }
\end{mathpar}
  \caption{Program typing}
  \label{fig:progtyping}
\end{figure}

\paragraph{Program typing.}
The typing of programs, written $Γ|- t : τ,ε$, assigns a type $τ$ and an
effect $ε$ to an expression $t$, given an environment. This typing is
presented in {\em A-normal form}, a normal form where all intermediate values
are \letml-introduced. All values are also programs with no effect (rule {\sc
Value}). An application must consist of two values and the effect of the
overall expression is precisely the effect of the called function (rule {\sc
App}). There are two rules for \letml, due to the value restriction. One only
can generalize type, effect and region variables when the bound expression is
a value. In this case (rule {\sc LetV}), only the second term may produe
effects. In the other case (rule {\sc Let}), no generalization takes place,
but both terms can have effects. The {\sc Let} rule actually obliges both
terms to have the same effect, but together with the {\sc Sub} rule, which can
increase the effect of an expression, this can always be achieved.
Finally, \ifml-expressions are typed in the usual way, both branches have to
have the same effect.

\paragraph{Logic typing.}

The typing of annotations is basically an extension of the typing for values;
logic terms never have any effect. To ensure this, we need to forbid calling
effectful functions in the logic. One way is to simply omit the typing rule
for effectful function calls. There is, however, another way which also
enables us to inspect the pre/ and postcondition of a function. To this end,
let us introduce the operation of {\em lifting} a type to the logic level (see
Fig.~\ref{fig:typelift}).
\begin{figure}[htpb]
  \begin{eqnarray*}
    \ceil{α} &=& α\\
    \ceil{τ~\refml_ρ} &=& \ceil{τ}~\refml_ρ\\
    \ceil{τ -> τ'} &=& \ceil{τ} -> \ceil{τ'}\\
    \ceil{τ \times τ'} &=& \ceil{τ} \times \ceil{τ'}\\
    \ceil{\efft{ε}} &=& \efft{ε}\\
    \ceil{τ ->^ε τ'} &=& (\ceil{τ} -> \efft{ε} -> \propml)\times (\ceil{τ} ->
    \efft{ε} -> \efft{ε} -> \ceil{τ'} -> \propml)
  \end{eqnarray*}
  \caption{Lifting types}
  \label{fig:typelift}
\end{figure}
This translation traverses the type and replaces all effectful types by a
tuple type which describes a tuple of a pre- and a postcondition. The
precondition takes as an argument the argument of the function as well as the
part of the store, at the moment of the function call, which corresponds to
the effect of the function. The postcondition's two first arguments are the
same, but in addition it expects the store {\em at the exit of the function},
as well as the function's return value.

\begin{figure}[htbp]
  \begin{mathpar}
  { \inferrule*[Left=Logic]
    { Γ |-_v t : τ  }
    { Γ |-_l t : \ceil{τ} }
  } \and
  { \inferrule*[Left=LetLogic]
    { Γ, \alist{χ} |-_l : t' : τ' \\ Γ, x: ∀\alist{χ}.τ' |-_l t : τ  }
    { Γ |-_l \letml~x~[\alist{χ}] = t'~\inml~t : τ }
  }\and
  { \inferrule*[Left=IteLogic]
    { Γ |- _l t1 : \boolml \\ Γ |-_l t2 : τ \\ Γ |-_l t3 : τ }
    { Γ |- \ifml~ t1 ~\thenml~ t2 ~\elseml ~ t3 : τ }
  }
  \end{mathpar}
  \caption{Logic typing}
  \label{fig:logictyping}
\end{figure}

Now we can come back to logic typing. Every value is also a logic term,
but now it is assigned its {\em lifted} type. The two other rules are just 
pure variants of their impure counterparts in the program typing.

\paragraph{Predefined constants.}

To actually be able to write programs in this language, we need many
predefined constants and types. The typing relations already mention two,
\propml\ and \boolml. \propml\ is the logical truth and contains the values
\Trueml\ and \Falseml, while \boolml\ describes boolean (decidable) properties
and contains \trueml\ and \falseml. The distinction between \propml\ and
\boolml\ is the same one as in \coq, for example. Properties expressed in
\propml\ are potentially undecidable and one cannot take decisions by testing
their truth value. On the other hand, \boolml\ talks about decidable
properties and so it makes sense to expect the predicate of the
\ifml-statement to be of type \boolml.

The reader may have wondered why the specification language does not contain
any logical connectives. These can of course be declared independently, for
example the conjuction is just a function: \begin{equation*} /\ :  \propml ->
  \propml -> \propml \end{equation*} Actually, when equality is given, all
  logical operations (even quantification) can be defined in the logic.
%TODO citation needed
In the remainder of the paper, we suppose predefined the usual logical
connectives conjunction, disjunction, implication and equivalence, as well as
universal and existential quantification. We also assume all the arithmetic
operations as well as the constructor $(t,t)$  and the accessors $fst$ and
$snd$ for pairs. 

% TODO TODO
%Finally, we introduce two symbols
%\begin{eqnarray*}
%  \oplus &:&∀ e1 e2 . \efft{ e1 } -> \efft{ e2 } -> \efft { e1  e2 }\\
%  |_{ε} &:& ∀ e. \efft{ e ε } -> \efft{ ε }.
%  !! & : & ∀αρ e. α~\refml_ρ -> \efft{ ρ e } -> α
%\end{eqnarray*}
%The first one denotes a combining operation for stores; the resulting store
%contains all the mappings of the second store, as well as all the mappings of
%the first one, as long as they are not present in the second one.
%union of the two arguments, in the sense that its domain is the union of its
%arguments.

\subsection{References}

We haven't mentioned references yet, but all we need to support them is to add
the three usual functions $ref, :=, !$ for reference creation, assignment and
lookup, respectively, to the environment. In our system, these functions have
the following types:
\begin{eqnarray*}
  ref &:& ∀αρ.α ->^ρ α~\refml_ρ\\
  := &:& ∀αρ.α~\refml_ρ ->^\emptyset α ->^ρ \unitml\\
  ! &:& ∀αρ. α~\refml_ρ ->^ρ α
\end{eqnarray*}

\subsection{Alias restriction}

The presented programming language, along with the specifications, can, in
fact be used to prove programs. The weakest precondition calculus presented in
the next section can be used to obtain proof obligations which, when proved,
guarantee the correctness of the program with respect to its specification. On
the other hand, in its presented form, and because of the presence of
aliasing, one would constantly need equalities and inequalities between
reference variables to be able to reason about a program.

\begin{figure}[htpb]
  \begin{mathpar}
    {\inferrule*[Left=Var]
      {Γ(x) = ∀\alist{χ}.τ \\ σ = [\alist{χ}|->\alist{κ}] \\ σ \sim τ }
      {Γ |- x : τσ }
    } \\
    { \inferrule*[Left=LetRef, Right={ρ \textup{fresh}, $ρ\notin τ$}]
      {Γ |-_v t1 : τ' \\ Γ, x : τ'~\refml_ρ |- t2 : τ, ε }
      {Γ |- \letml~x = ref~ t1 ~\inml~ t2 : τ, ε \setminus ρ}
    }
  \end{mathpar}
  \caption{A modified and a new rule for aliasing}
  \label{fig:aliasing}
\end{figure}

A way out is to restrict programs to alias free programs. Fortunately, it is
easy to modify the presented typing rules to render all programs with aliasing
ill-typed (see Fig~\ref{fig:aliasing}). In the following, we will use regions
to identify memory locations entirely; each region shall describe precisely
one memory location. Starting from this assumption, a program can actually
exhibit {\em two} forms of aliasing. In the first one, it may use several
names (region variables) for the same memory location. This can happen when a
function is generalized over, say, two region variables, assuming they are
different, and is then instantiated with the same region variable twice. The
classical example is the following program
%TODO

which is only correct if $ ρ1 $ and $ ρ2 $ are indeed different. To enforce
this, we add a side condition to the instantiation: the substitution $σ$ must
be {\em compatible} with the type $τ$. To understand what compatibility means,
consider an {\em atomic} substitution $[ρ|->ρ']$. It is compatible with any
type which does not contain $ρ'$. Similarly, the substitution $[e|-> ρ1  ρ2
e'$] is compatible with any type which does not contain $ ρ1 , ρ2 $ nor $e'$.
Expressed more generally, an atomic substitution is compatible with a type if
the type does not contain any region or effect variables which are in the
range of the substitution. Finally, a composite substitution is compatible
%TODO atomic and composite
with a type if each atomic substitution is compatible with the result of the
application of the previous substitution. In this way, it becomes impossible
to have different names for a single reference cell.

The second form of aliasing is when we use the same name for {\em different}
memory locations. This can happen when we allow the user to call $ref$ several
times with the same region instantiation. A simple possibility is to attach
the suppress the $ref$ function entirely and to replace it by a \letml\refml\ 
construct which combines name creation and memory allocation. In this way,
there can of course be only one reference per name. On the other hand, because
of the side condition $ρ\notin τ$, the reference cannot escape the scope of
its \letml\refml\ construct, and so, a function cannot return a reference
which has been created in its body. This restriction could be leveraged a bit if
one seperates name creation and allocation, while still maintaining that one
can only allocate a single reference in each region. This is how it is done in
the correctness proof of this restriction. The presented \letml\refml\
construct is of course a special case.
%TODO now, all operations on maps can be statically resolved.

\subsection{Some properties}

%TODO
$Γ|-_v v : τ$ implies $Γ |-_l \ceil{v} : \ceil{τ}$

Subject reduction of our type system is a consequence of subject reduction of
the region calculus of Tofte/Talpin~\cite{tofte97ic}.

\section{A Simple Weakest Preconditions Calculus}

The aim of the weakest precondition calculus is to obtain proof obligations
from the annotated program. To do this, the calculus starts from a formula
which holds, or is supposed to hold, at the end of the program, and walks
backwards in the program source to obtain the weakest formula which has to
hold at the beginning of the program (hence the name {\em weakest
precondition}. 

In the following, we use the metasymbol $v$ to denote well-typed values, i.e.
terms with a typing derivation $Γ|-_v v : τ$. In the definition of the weakest
precondition calculus, we will use the notation $(t : τ, ε)$ to denote that
$t$ has type $τ$ and effect $ε$. We assume that applications of the
subeffecting rule {\sc Sub} rule are explicitely inserted in the term; they
are written $(t:ε<:ε')$.

\begin{figure}[htbp]
  \begin{eqnarray*}
    \ceil{x~[\alist{κ}]} &=& x~[\alist{κ}]\\
    \ceil{λx:τ.t} &=& λx:τ.\ceil{t}\\
    \ceil{\recml~f~(x:τ).\{p\} t \{q\}} &=& 
    (λx:\ceil{τ}.p,λx:\ceil{τ}.q)\\
    \ceil{t_{τ' -> τ}~t'} &=& \ceil{t}~\ceil{t'}
  \end{eqnarray*}
  \caption{Lifting values}
  \label{fig:valuelift}
\end{figure}

First of all, analogous to the lifting of types to the logic level, we define
a lifting of values to the logic level. Similarly, this translation traverses
the value until it encounters an impure function. From the logic point of
view, an impure function is represented by its specification, so the
translation keeps only the pair of pre- and postcondition, both abstracted
over the function argument. The function body is thrown away.

\begin{figure}[htbp]
  \begin{eqnarray*}
    c(x~[\alist{κ}]) &=& \Trueml \\
    c(λx:τ.t) &=& ∀x:\ceil{τ}.c(t) \\
    c(t~t') &=& c(t) /\ c(t') \\
    c(\recml~f~(x:τ).\{p\}(t : τ',ε)\{q\}) &=&
    ∀x:\ceil{τ}.∀f:\ceil{τ->^ετ'}.  f = \ceil{v} => \\& &
    ∀s:\efft{ε}.p~s => \wpre_s(t,q~s) \\
    \wpre_s(v, q) &=& c(v) /\ q~s~\ceil{v}\\
    \wpre_s( t_{τ'->^ε τ} t' ,q) &=& \correct{t} /\ \correct{t'} /\
    fst~\ceil{t}~\ceil{t'}~s /\ \\ 
    & & ∀s':\efft{ε}∀ x:\ceil{τ}.~  snd~\ceil{t}~\ceil{t'}~s~s'~x => q~s'~x\\
    \wpre_s(\letml~x~[\alist{χ}] = v~\inml~t, q) &=&
      ∀\alist{χ}.c(v) /\ \letml~x~[\alist{χ}]=\ceil{v}~\inml~ \wpre(t,q)\\
    \wpre_s(\letml~x = ( t1 : τ,ε) ~\inml~ t2 , q) &=&
    \wpre_s( t1 ,λs':\efft{ ε }.λx:\ceil{τ}.\wpre_{s'}( t2 , q ))\\
    \wpre_s(\ifml~ t1 ~\thenml~ t2 ~\elseml~ t3 , q) &=&
      \ifml~ \ceil{ t1 }~\thenml~ \wpre_s( t2 , q))~\elseml~\wpre_s( t3 , q)) \\
      \wpre_s( (t : ε <: ε'), q) &=& \wpre_{s|_ε}(t, λs':\efft{ε}.q~(s\oplus s'))
  \end{eqnarray*}
  \caption{The weakest precondition calculus}
  \label{fig:wp}
\end{figure}

The weakest precondition calculus itself comes in two parts, one for values
and one for effectful terms. Both are reasonably straightforward. The {\em
correctness} of values, written $c(v)$, ensures that any effectful function
appearing in a value adheres to its specification. To this end, the value is
traversed, quantifying over bound variables and using conjunction for pure
applications. When an effectful function is encountered, one has to prove that
the precondition of the function implies the postcondition, given the function
body.

The part concerning effectful functions, denoted $\wpre_s(t,q)$ takes as
argument a term $t$ of type $τ$ and effect $ε$, a postcondition $q$ of type
$\efft{ε} -> τ -> \propml$ and a current state $s$ of type $\efft{ε}$. If the
term is in fact a value, the value has to be correct and the postcondition
must be true for the lifted value and the current state. In the case of an
application, both values must be correct, the precondition of the function
must hold in the current state, and for any state and return value of the
function, the function's postcondition must imply the condition $q$ to be
proved.

As for the typing relation, we have two rules for the \letml-binding. If the
bound term is a value, we can translate the \letml-binding in the program by a
\letml-binding in the language. In the other case, the \wpre\ of $ t2 $ becomes
the argument of the \wpre of $ t1 $ (we denote $ε$ the effect of $ t1 $ and $
t2 $). The rule for \ifml-expressions is straightforward. The rule for
subeffecting adapts the domain of the current store and the expected domain of
the postcondition so that the types work out.

\section{Extensions}

subtyping: effects

\section{Implementation}

%what has been implemented

A prototype implementation by the name ``\who''
exists~\cite{KanigFilliatre09wml} and is freely available. It implements the
described language with type, region and effect polymorphism, higher-order
logics and store types in the logic. It takes as an input a fully annotated
program and outputs proof obligations which have to be proved to guarantee the
correctness of the program with respect to its specification. Currently, only
output to the interactive proof assistant Coq has been implemented. Our logic
is a subset of Coq's, so the translation is particularly simple.

%details
% lines of code : less than 3000 lines of ocaml
% limited form of type and effect inference
% 

\section{Examples}

\begin{center}
    \begin{tabular}{ | r | r | r | r |}
    \hline
    Program & Code & Spec & Proofs \\ \hline
    Array &  &  &  \\
    Hashtbl & & &  \\ \hline
    Memo/Ymemo & & &  \\ \hline
    Koda-Ruskey~\cite{KanigFilliatre09wml} & & &  \\ \hline
    \end{tabular}
\end{center}

\subsection{memo}
\subsection{ymemo}

\section{Related Work}

\section{Conclusion}

\paragraph{Future Work.}

We are currently investigating the possibility to obtain first-order proof
obligations, to be able to use SMT solvers~\cite{RanTin-SMTLIB}, which would
avoid manual proofs in many cases. An obvious solution would be to reuse
existing encodings of higher-order logic in first-order logic, such as the one
by Pottier and Gauthier~\cite{pottier-gauthier-hosc}. This technique has been
successfully employed by the Pangolin system~\cite{regis-gianas-pottier-08}.
Another option comes from our observation that in many cases, the proof
obligations for higher-order functions can actually be expressed in
first-order logic, when one replaces top-level {\em quantifications} of
functional arguments and invariants by top-level {\em declarations}. Doing
this translation manually, we have obtained first-order proof
obligations for the {\tt Array.iter} function which are all discharged by
SMT solvers. We don't know if such a transformation can always be carried out.

what about correspondence between $τ ->^\emptyset τ$ and $τ -> τ$?

\bibliographystyle{plain}
\bibliography{biblio}{}

\end{document}
